{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most significant adjectives for men / women\n",
    "\n",
    "__What's the difference in describing men and women?__\n",
    "\n",
    "And in more technical terms: \n",
    "\n",
    "__What are the most significant adjectives used with the word 'man' as opposed to the word 'woman'?__\n",
    "\n",
    "\n",
    "The general approach would be:\n",
    "- use the standard NLTK corpora representing free text (eg gutenberg, brown, webtext)\n",
    "- count the occurences of every word preceding 'man' or 'woman' (let's call them adjectives)\n",
    "- sort by the 'most significant' adjective, that is one that is most 'uncommonly common' for a given category - man or woman\n",
    "- show them\n",
    "\n",
    "## Technologies\n",
    "- **NLTK** for NLP\n",
    "- **pandas** for 'most-significant' calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[(u'every', 327), (u'young', 266), (u'old', 207), (u'one', 72), (u'another', 42), (u'little', 38), (u'wise', 34), (u'certain', 33), (u'good', 31), (u'poor', 30)], [(u'old', 61), (u'young', 57), (u'every', 10), (u'strange', 9), (u'poor', 9), (u'certain', 8), (u'another', 7), (u'good', 6), (u'lovely', 6), (u'charming', 6)]], [[(u'old', 53), (u'young', 47), (u'one', 25), (u'big', 17), (u'fat', 11), (u'every', 10), (u'good', 9), (u'little', 9), (u'white', 8), (u'common', 7)], [(u'old', 13), (u'young', 11), (u'another', 5), (u'every', 3), (u'strange', 3)]], [[(u'old', 86), (u'black', 19), (u'white', 16), (u'young', 12), (u'hey', 10), (u'blind', 9), (u'yeah', 8), (u'tourist', 7), (u'good', 6), (u'vendor', 5)], [(u'old', 51), (u'black', 26), (u'young', 23), (u'tourist', 13), (u'southern', 12), (u'aged', 10), (u'white', 9), (u'drunk', 7), (u'italian', 6), (u'ghetto', 5)]]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "import pandas as pd\n",
    "\n",
    "def most_common_adj(corpus, word, limit=10, min_freq=3):\n",
    "    # bigrams ending with word\n",
    "    bigrams = nltk.bigrams(corpus.words())\n",
    "    adjectives = [x.lower() for x,y in list(bigrams) if y==word]\n",
    "    fd = nltk.FreqDist([w for w in adjectives if len(w)>2 and w not in stopwords])\n",
    "    return [ (word, freq) for word,freq in fd.most_common(limit) if freq >= min_freq ]\n",
    "    \n",
    "words = [\"man\", \"woman\"]\n",
    "corpuses = [nltk.corpus.gutenberg\n",
    "            , nltk.corpus.brown, nltk.corpus.webtext\n",
    "           ]\n",
    "most_common = [[most_common_adj(corpus, word, limit=1000, min_freq=3) for word in words] for corpus in corpuses]\n",
    "\n",
    "print [[word_counts[:10] for word_counts in corpus] for corpus in most_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------\n",
      "Project Gutenberg Selections\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "man: -------------\n",
      "little,mighty,wicked,rich,great,righteous,sensible,honest,blind,lazy,first,mortal,white,upon,euery,strong,tall,prudent,honourable,evil,dead,valiant,married,foolish,agreeable,never,ordinary,grey,last,violent,elderly,upright,slothful,small,brave,third,drunken,industrious,neither,thou,hearted,without,unto,big,happy,made,average,single,faithful,whatsoever,large,new,hairy,clever,known,perfect,better,haired,free,created,bad,like,lean,wayfaring,mean,sick,excellent,bloody,armed,crazy,lame,short,furious,inward,unhappy,happiest,dumb,best,faced,yet,tempered,respectable,fellow,impatient,every,one,wise,another,good,young,looking,certain,old,poor,natured,strange\n",
      "\n",
      "woman: -------------\n",
      "lovely,charming,widow,fine,virtuous,midianitish,beautiful,israelitish,amiable,strange,natured,poor,old,certain,looking,young,good,another,wise,one,every\n",
      "\n",
      "-------------------------------------\n",
      "BROWN CORPUS\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "man: -------------\n",
      "one,big,fat,good,little,white,common,dead,thin,middle-aged,insurance,business,great,honest,small,best,learned,blind,station,tall,waspish,third,young,old,every,another\n",
      "\n",
      "woman: -------------\n",
      "strange,another,every,old,young\n",
      "\n",
      "-------------------------------------\n",
      "Web Text Corpus\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "man: -------------\n",
      "hey,blind,yeah,good,vendor,homeless,american,every,large,yarmulke,shit,nah,white,old,older,crazy,black,ghetto,tourist,young,italian,aged,southern\n",
      "\n",
      "woman: -------------\n",
      "drunk,island,british,yuppie,younger,asian,elderly,sober,jappy,french,pregnant,thirtysomething,southern,aged,italian,young,tourist,ghetto,black,crazy,older,old,white\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def most_significant(groups, limit=10):\n",
    "    \"\"\" Sorts adjectives in each group with most significant for the group first\n",
    "    \n",
    "        most significant means occurring in the group more often than in the whole corpus\n",
    "        significance ranges from [0 to 1], 1 meaning that the adjective doesn't exist anywhere else but in this group\n",
    "        NOTE: if two words have the same significance then the one occurring more often is more significant\n",
    "    \"\"\"\n",
    "    dfs = [pd.DataFrame(group, columns=['word', 'counts']) for group in groups]\n",
    "    dfs = [df.set_index('word') for df in dfs]\n",
    "    \n",
    "    #     adjustment is required to remove bias caused by some groups being more populous\n",
    "    biggest_count = max([sum(df.counts) for df in dfs])\n",
    "    dfs = [df*biggest_count/sum(df.counts) for df in dfs]\n",
    "    \n",
    "    total = reduce(lambda x,y: x.add(y, fill_value=0), dfs)\n",
    "    for df in dfs:\n",
    "        df['ratio'] = df/total\n",
    "        \n",
    "    sigs = [df.dropna().to_records().tolist() for df in dfs]\n",
    "    sorted_sigs = [ sorted(sig, key=lambda x: (x[2],x[1]), reverse=True) for sig in sigs ]\n",
    "    return [ sig[:limit] for sig in sorted_sigs ]\n",
    "    \n",
    "\n",
    "for corpus, corpus_most_common in zip(corpuses, most_common):\n",
    "    print \"\\n-------------------------------------\\n{}\\n-------------------------------------\\n\".format(corpus.readme().split('\\n')[0])\n",
    "    for word, word_most_significant in zip(words, most_significant(corpus_most_common, limit=100)):\n",
    "#         print \"\\n{}: -------------\\n{}\".format(word, word_most_significant)\n",
    "            print \"\\n{}: -------------\\n{}\".format(word, \",\".join(map(lambda x: x[0], word_most_significant)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
